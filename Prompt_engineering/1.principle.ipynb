{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guidelines for Prompting\n",
    "In this lesson, you'll practice two prompting principles and their related tactics in order to write effective prompts for large language models.\n",
    "\n",
    "## Setup\n",
    "#### Load the API key and relevant Python libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, we've provided some code that loads the OpenAI API key for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### helper function\n",
    "Throughout this course, we will use OpenAI's `gpt-3.5-turbo` model and the [chat completions endpoint](https://platform.openai.com/docs/guides/chat). \n",
    "\n",
    "This helper function will make it easier to use prompts and look at the generated outputs.  \n",
    "**Note**: In June 2023, OpenAI updated gpt-3.5-turbo. The results you see in the notebook may be slightly different than those in the video. Some of the prompts have also been slightly modified to product the desired results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This and all other lab notebooks of this course use OpenAI library version `0.27.0`. \n",
    "\n",
    "In order to use the OpenAI library version `1.0.0`, here is the code that you would use instead for the `get_completion` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "# def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "#     messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=model,\n",
    "#         messages=messages,\n",
    "#         temperature=0\n",
    "#     )\n",
    "#     return response.choices[0].message.content\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "def get_completion(prompt, model=\"Qwen/QwQ-32B\"):\n",
    "    llm=HuggingFaceEndpoint(repo_id=model,\n",
    "                        task=\"text-generation\"\n",
    "                        )\n",
    "    model=ChatHuggingFace(llm=llm)\n",
    "    result=model.invoke(prompt)\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting Principles\n",
    "- **Principle 1: Write clear and specific instructions**\n",
    "- **Principle 2: Give the model time to “think”**\n",
    "\n",
    "### Tactics\n",
    "\n",
    "#### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
    "- Delimiters can be anything like: ```, \"\"\", < >, `<tag> </tag>`, `:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I need to summarize this text into a single sentence. Let me read through it again to get the main points. The text is about how to give effective instructions to a model. The key ideas are that instructions should be as clear and specific as possible to guide the model correctly and avoid irrelevant answers. It also mentions that longer prompts can actually help by providing more context, even though clarity isn't just about being short.\n",
      "\n",
      "Hmm, so the main goal here is to convey that clear and specific instructions, even if detailed, lead to better model outputs. The summary should include the importance of clarity and specificity, the benefit of reducing errors, and the note that longer prompts can be helpful. Let me try combining these elements into one sentence without missing any crucial points.\n",
      "\n",
      "Wait, does the original text say that longer prompts are better because they offer more clarity? Yes, it says longer prompts can provide more clarity and context, leading to better outputs. So I need to include that longer prompts aren't bad and actually beneficial. \n",
      "\n",
      "How about: \"To ensure models produce accurate and relevant responses, provide clear, specific, and detailed instructions, as longer prompts often enhance clarity and context, leading to better outputs.\" \n",
      "\n",
      "Let me check if that captures all the main points: clear, specific instructions reduce irrelevant/incorrect responses, and longer prompts are okay because they add clarity and context. Yep, that seems to cover it. Maybe I can make it more concise. \"For models to generate accurate responses, use clear, specific, detailed instructions as longer prompts often provide needed clarity and context, improving relevance.\" \n",
      "\n",
      "Is that one sentence? Yes. It includes the key actions (use clear, specific, detailed), the benefit of longer prompts, and the outcome (better relevance). I think that works.\n",
      "</think>\n",
      "\n",
      "To ensure models produce accurate and relevant responses, provide clear, specific, and detailed instructions, as longer prompts often enhance clarity and context, leading to more precise outputs.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \n",
    "providing instructions that are as clear and \n",
    "specific as you can possibly make them. \n",
    "This will guide the model towards the desired output, \n",
    "and reduce the chances of receiving irrelevant \n",
    "or incorrect responses. Don't confuse writing a \n",
    "clear prompt with writing a short prompt. \n",
    "In many cases, longer prompts provide more clarity \n",
    "and context for the model, which can lead to \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To ensure models produce accurate and relevant responses, provide clear, specific, and detailed instructions, as longer prompts often enhance clarity and context, leading to more precise outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tactic 3: Ask the model to check whether conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 1:\n",
      "Okay, let me see. The user wants me to take the provided text and check if it has a sequence of instructions. If so, I need to rewrite those steps in the specified format. Otherwise, just say \"No steps provided.\"\n",
      "\n",
      "Looking at the given text about making tea. The first sentence says \"Making a cup of tea is easy! First, you need to get some water boiling.\" The word \"First\" is a big clue here that there's a step-by-step process. Let me read through the rest.\n",
      "\n",
      "The next part mentions \"While that's happening, grab a cup and put a tea bag in it.\" So that's the second step, maybe? Then, \"Once the water is hot enough, pour it over the tea bag.\" That's step 3. Next, \"Let it sit for a bit so the tea can steep.\" Definitely a step. Then \"After a few minutes, take out the tea bag.\" Step 4. Then adding sugar or milk is optional, but still a step. And finally, the conclusion.\n",
      "\n",
      "So the steps are:\n",
      "\n",
      "1. Boil water.\n",
      "2. Put tea bag in a cup while waiting.\n",
      "3. Pour hot water over the tea bag.\n",
      "4. Let it steep.\n",
      "5. Remove tea bag after a few minutes.\n",
      "6. Add sugar or milk if desired.\n",
      "\n",
      "I need to format each as Step X - ... Be concise, capture each action. Also, check if any steps are combined. For example, step 2 is doing two actions: grab a cup and put the tea bag. But since they are done together, maybe combine into a single step. The original uses \"grab a cup and put a tea bag...\" so that's one step. Same with adding sugar or milk as an optional final step.\n",
      "\n",
      "So numbering each instruction in order. Let me write them out properly.\n",
      "</think>\n",
      "\n",
      "Step 1 - Boil water.  \n",
      "Step 2 - Place a tea bag in a cup.  \n",
      "Step 3 - Pour the hot water over the tea bag.  \n",
      "Step 4 - Let the tea steep for a few minutes.  \n",
      "Step 5 - Remove the tea bag from the cup.  \n",
      "Step 6 - Add sugar or milk to taste, if desired.\n"
     ]
    }
   ],
   "source": [
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some \n",
    "water boiling. While that's happening, \n",
    "grab a cup and put a tea bag in it. Once the water is \n",
    "hot enough, just pour it over the tea bag. \n",
    "Let it sit for a bit so the tea can steep. After a \n",
    "few minutes, take out the tea bag. If you \n",
    "like, you can add some sugar or milk to taste. \n",
    "And that's it! You've got yourself a delicious \n",
    "cup of tea to enjoy.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 2:\n",
      "Okay, let's see what the user is asking here. They provided a query where they want me to check a given text for a sequence of instructions. If there are instructions, I need to rewrite them in numbered steps. If not, just say \"No steps provided.\"\n",
      "\n",
      "The text they provided is a descriptive paragraph about a beautiful day with the sun shining, birds singing, people in the park, etc. I need to determine if this contains any step-by-step instructions. \n",
      "\n",
      "First, I'll read through the text again. It starts with the sun and birds, then mentions it's a beautiful day to go for a walk. Then it describes the flowers, trees, people activities like picnics, games, relaxing. The last sentence says it's a perfect day to spend time outdoors and appreciate nature. \n",
      "\n",
      "Hmm, the key here is to check for instructions. Instructions are typically verbs that tell someone to do something in a sequence. Let's look for action words. The phrases like \"go for a walk\", \"having picnics\", \"playing games\", \"relaxing\" are more descriptions of activities people are doing, not stepped-out instructions. The sentence \"It's a beautiful day to go for a walk in the park.\" is a suggestion but not an instruction. Similarly, \"It's a perfect day to spend time outdoors...\" is an advice or recommendation, not a set of steps to follow.\n",
      "\n",
      "Since there are no numbered lists or sequential actions like \"first do this, then that\", just a vivid description of a day, there's no actual instructional steps here. The user's instruction is to only format the steps if there's a sequence of instructions. Since this text doesn't have that, the correct response is \"No steps provided.\"\n",
      "\n",
      "I should make sure I'm not missing any hidden instructions. Maybe the part \"go for a walk\" could be seen as a step, but it's just one action. The rest are concurrent activities, not a sequence. So yes, the answer is definitely \"No steps provided.\"\n",
      "</think>\n",
      "\n",
      "No steps provided.\n"
     ]
    }
   ],
   "source": [
    "text_2 = f\"\"\"\n",
    "The sun is shining brightly today, and the birds are \n",
    "singing. It's a beautiful day to go for a \n",
    "walk in the park. The flowers are blooming, and the \n",
    "trees are swaying gently in the breeze. People \n",
    "are out and about, enjoying the lovely weather. \n",
    "Some are having picnics, while others are playing \n",
    "games or simply relaxing on the grass. It's a \n",
    "perfect day to spend time outdoors and appreciate the  \n",
    "beauty of nature.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 2:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tactic 4: \"Few-shot\" prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user wants me to respond to the child's question about resilience in the same style as the previous answer about patience. Let me look at the original example again.\n",
      "\n",
      "The grandparent used three metaphors: river to valley, symphony from a note, tapestry from a thread. Each is a natural or artistic process that starts small and grows into something significant. The key elements are the contrast between the humble beginnings and the impressive end result, illustrating patience.\n",
      "\n",
      "Now, for resilience, I need metaphors that show overcoming challenges or bouncing back. Let me brainstorm some ideas. Maybe something like a tree that bends in the wind but doesn't break, a phoenix rising from ashes, or a river that overcomes rocks to keep flowing. Wait, the river was already used for patience. Let me think of others.\n",
      "\n",
      "A mountain is formed through the pressure of tectonic plates, enduring forces over time. Or a butterfly breaking free from a chrysalis. A candle flame that flickers but stays lit in the wind. Maybe the phoenix is good but a bit cliché. The mountain's endurance could work. Let's structure each metaphor to show struggle leading to strength.\n",
      "\n",
      "First example: The mountain that stands tallest has weathered the fiercest storms. Second: The flame that burns longest has danced with the wildest winds. Third: The oak that grips the steepest cliff began as a acorn defying gravity. Each starts with the outcome, then the struggle, similar to the original. Need to make sure the structure mirrors the patience example exactly. \n",
      "\n",
      "Check syllable count? Not sure, but the flow is important. \"The mountain peak that touches the sky once clenched fists under glaciers...\" Hmm, maybe \"The mountain that towers highest overcame glaciers' icy grip; the flame that endures stormiest nights bends but never surrenders; the oak that grips the steepest cliff grew from a seed that cracked bedrock.\" That seems to fit. Each starts with the majestic result, then the challenge it overcame. Yes, that should work. Let's put it together.\n",
      "</think>\n",
      "\n",
      "<grandparent>: The mountain that towers highest overcame glaciers' icy grip; the flame that endures stormiest nights bends but never surrenders; the oak that grips the steepest cliff grew from a seed that cracked bedrock.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest \n",
    "valley flows from a modest spring; the \n",
    "grandest symphony originates from a single note; \n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\n",
    "\n",
    "\n",
    "Please remove your thinking procedure from the response\n",
    "Please do above final step\n",
    "\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle 2: Give the model time to “think” \n",
    "\n",
    "#### Tactic 1: Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/tmp/ipykernel_10156/99030377.py:11: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 1:\n",
      "Okay, I need to tackle this problem step by step. Let's start with the first action: summarizing the given text in one sentence. The text is about Jack and Jill going to fetch water from a hilltop well, having an accident where they both fall down the hill, but they come home safely and still keep exploring. So the summary should capture the main points: their quest, the accident, and their resilience.\n",
      "\n",
      "Hmm, maybe something like: \"Jack and Jill went to fetch water from a hilltop well but had an accident while climbing, resulting in them tumbling down the hill, though they returned home safely and continued their explorations with undimmed spirits.\" That's a bit long, but it's one sentence.\n",
      "\n",
      "Next, translating that summary into French. Let's see. \"Jack et Jill sont allés chercher de l'eau à une pompe en haut d'une colline mais ont eu un accident en montant, tombant tous les deux, mais sont rentrés sain et sauf et ont continué leurs explorations avec autant d'entrain.\" Wait, need to check the verb tenses and some vocabulary. Maybe \"partis en quête\" instead of \"sont allés chercher\"? Or \"ont entrepris une quête\"? \"Tombé dans la colline\" might need \"de la colline\". Maybe \"tombèrent de la colline\" for past. Let me adjust: \"Jack et Jill, partis en quête d'eau à une fontaine sur une colline, ont eu un accident en grimpant, tombant tous deux, mais ont rentrés chez eux sains et saufs et ont poursuivi leurs explorations avec autant de joie.\" Not sure if \"fontaine\" is right; maybe \"puits\"? \"un puits au sommet d'une colline\". \"sains et saufs\" is correct. Also, the original mentions \"fetch water from a hilltop well\", so \"un puits au sommet d'une colline\". Maybe: \"Jack et Jill sont partis chercher de l'eau à un puits sur une colline, mais ont eu un accident en grimpant, tombant ensemble, mais sont rentrés sains et saufs et ont continué d'explorer avec la même ardeur.\"\n",
      "\n",
      "Third step: list each name in the French summary. The names are Jack and Jill. So the list would be [\"Jack\", \"Jill\"].\n",
      "\n",
      "Lastly, create a JSON object with keys \"french_summary\" and \"num_names\", which is the number of names. So the JSON would be:\n",
      "\n",
      "{\n",
      "  \"french_summary\": \"the translated sentence\",\n",
      "  \"num_names\": 2\n",
      "}\n",
      "\n",
      "Wait, but need to ensure in the French summary I have the accurate translation. Let me go back. The original summary was: \"Jack and Jill went to fetch water from a hilltop well but had an accident while climbing, resulting in them tumbling down the hill, though they returned home safely and continued their explorations with undimmed spirits.\"\n",
      "\n",
      "In French, maybe: \"Jack et Jill sont partis chercher de l'eau à un puits au sommet d'une colline, mais ont eu un accident en grimpant et sont tombés de la colline, bien qu'ils soient rentrés sains et saufs et aient continué leurs explorations avec autant d'entrain.\"\n",
      "\n",
      "That might be better. So the names are indeed Jack and Jill, so two names. The JSON would have the French summary as that sentence and num_names:2.\n",
      "\n",
      "Let me check again for any mistakes. The accident led to them tumbling down, and they returned home. \"bien qu'ils soient rentrés\" uses the subjunctive? Wait, \"bien que\" takes indicative if the subject is the same, so \"bien qu'ils soient\" is correct. \"continué leurs explorations avec autant d'entrain\" sounds good. Okay.\n",
      "</think>\n",
      "\n",
      "1 - Jack and Jill went to fetch water from a hilltop well but had an accident while climbing, resulting in them tumbling down the hill, though they returned home safely and continued their explorations with undimmed spirits.  \n",
      "2 - Jack et Jill sont partis chercher de l'eau à un puits sur une colline, mais ont eu un accident en grimpant et sont tombés, bien qu'ils soient rentrés sains et saufs et aient poursuivi leurs explorations avec autant d'entrain.  \n",
      "3 - [\"Jack\", \"Jill\"]  \n",
      "4 - {  \n",
      "  \"french_summary\": \"Jack et Jill sont partis chercher de l'eau à un puits sur une colline, mais ont eu un accident en grimpant et sont tombés, bien qu'ils soient rentrés sains et saufs et aient poursuivi leurs explorations avec autant d'entrain.\",  \n",
      "  \"num_names\": 2  \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \n",
    "a quest to fetch water from a hilltop \n",
    "well. As they climbed, singing joyfully, misfortune \n",
    "struck—Jack tripped on a stone and tumbled \n",
    "down the hill, with Jill following suit. \n",
    "Though slightly battered, the pair returned home to \n",
    "comforting embraces. Despite the mishap, \n",
    "their adventurous spirits remained undimmed, and they \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple \n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following \n",
    "keys: french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt_1)\n",
    "print(\"Completion for prompt 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ask for output in a specified format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completion for prompt 2:\n",
      "Okay, so I need to handle this task step by step. Let's start with the first step: summarizing the given text into one sentence. The text is about Jack and Jill going to fetch water from a hilltop well, having an accident where Jack trips and they both fall down the hill, but they come home okay and still keep exploring. The summary needs to capture all that in a single sentence. Hmm.\n",
      "\n",
      "Maybe something like: \"Jack and Jill, siblings from a charming village, went to fetch water from a hilltop well but had an accident where Jack tripped, causing both to fall down the hill, though they returned home safely and continued their adventures.\" That seems to cover the main points: who they are, the quest, the accident, the outcome, and their spirit.\n",
      "\n",
      "Next step is translating this summary into French. Let me check the translation. \"Jack et Jill, frères et sœurs d'un village charmant, sont partis chercher de l'eau à une fontaine en haut d'une colline mais ont eu un事故 où Jack a trébuché, entraînant leur chute tous les deux, bien qu'ils soient rentrés sains et saufs et ont poursuivi leurs aventures.\" Wait, maybe \"accident\" is \"un accident\" instead of 事故, which is Japanese. Oh right, I should correct that. So \"eu un accident\". Also \"frères et sœurs\" might be redundant since Jack and Jill are siblings; maybe just \"les frère et sœur Jack et Jill\" for clarity. Let me rephrase: \"Jack et Jill, frère et sœur d'un village charmant, sont partis chercher de l'eau à une fontaine en haut d'une colline mais ont eu un accident où Jack a trébuché, causant leur chute tous les deux, bien qu'ils soient rentrés sains et saufs et aient continué leurs aventures.\" That sounds better.\n",
      "\n",
      "Third step: list each name in the French summary. The names here are Jack and Jill. The rest are common nouns or verbs. So the names are [\"Jack\", \"Jill\"].\n",
      "\n",
      "Then, create a JSON object with keys french_summary and num_names. The number of names is 2. I need to ensure that the JSON is correctly formatted. Let me check the French translation again for accuracy. \"sont partis chercher\" is correct for \"went to fetch.\" \"ont eu un accident où Jack a trébuché, causant leur chute...\" Maybe \"ce qui a causé\" instead of \"causant\" but \"causant\" is an participle, so \"causant leur chute\" is okay. Alternatively, \"provoquant leur chute.\" Maybe \"causant\" is okay. I'll stick with that.\n",
      "\n",
      "So compiling everything: the summary in one sentence, translate into French, list the names, then JSON. Let me make sure I didn't miss any names in the French version. The names are only Jack and Jill. The others are village, hilltop well, etc., which are not names. So that's correct. Alright, I think that's all. Let me put it into the required format.\n",
      "</think>\n",
      "\n",
      "Summary: Jack and Jill, siblings from a charming village, tried to fetch water from a hilltop well but had an accident while climbing, resulting in injuries but no loss of adventurous spirit.  \n",
      "Translation: Jack et Jill, frère et sœur d'un village charmant, ont tenté de chercher de l'eau dans une fontaine en haut d'une colline mais ont eu un accident en grimpant, entraînant des blessures mineures sans altérer leur esprit aventureux.  \n",
      "Names: [\"Jack\", \"Jill\"]  \n",
      "Output JSON: {\"french_summary\": \"Jack et Jill, frère et sœur d'un village charmant, ont tenté de chercher de l'eau dans une fontaine en haut d'une colline mais ont eu un accident en grimpant, entraînant des blessures mineures sans altérer leur esprit aventureux.\", \"num_names\": 2}\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "Your task is to perform the following actions: \n",
    "1 - Summarize the following text delimited by \n",
    "  <> with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the \n",
    "  following keys: french_summary, num_names.\n",
    "\n",
    "Use the following format:\n",
    "Text: <text to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Names: <list of names in summary>\n",
    "Output JSON: <json with summary and num_names>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "response = get_completion(prompt_2)\n",
    "print(\"\\nCompletion for prompt 2:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let me try to figure this out. The student's solution is given, and I need to check if it's correct. The question is about calculating the total first-year cost for a solar power installation based on the square footage. \n",
      "\n",
      "First, let's go through the problem again step by step to make sure I understand all the costs involved. The costs mentioned are land, solar panels, and maintenance. \n",
      "\n",
      "Land costs $100 per square foot. So if the installation is x square feet, that should be 100 times x, right? The student wrote Land cost as 100x, so that looks correct.\n",
      "\n",
      "Next, the solar panels cost $250 per square foot. So similarly, that's 250x. The student's Solar panel cost is 250x, which matches. \n",
      "\n",
      "Now, the maintenance cost has two parts: a flat $100,000 per year and an additional $10 per square foot. The flat fee is straightforward, so that's 100,000. The variable part should be 10 times x. The student's maintenance cost is written as 100,000 + 100x. Wait, hold on! That's where the mistake might be. The problem says $10 per square foot for the additional part, but the student wrote 100x. Oh, so the student probably made an error here. The maintenance should be 100,000 + 10x, not 100x. That would make their total cost calculation wrong.\n",
      "\n",
      "So the student's breakdown for maintenance is incorrect. Let me check the total cost again according to the student: 100x (land) + 250x (panels) + (100,000 + 100x) (maintenance). Adding these together gives 100+250+100 = 450x plus 100,000. But since the maintenance's variable cost is actually $10 per square foot, not $100, that term should be 10x instead of 100x. So the correct total cost should be (100 + 250 + 10)x + 100,000, which would be 360x + 100,000. \n",
      "\n",
      "Therefore, the student incorrectly converted the $10/sq ft maintenance cost into $100/sq ft, leading to an overestimation of the variable costs by a factor of 10. That's a significant error because it changes the slope of the cost function. \n",
      "\n",
      "Wait, let me double-check the problem's wording again to make sure I didn't misinterpret anything. The maintenance cost is a flat $100k per year plus an additional $10 per square foot. Yes, so the per square foot for maintenance is $10, so that's definitely a mistake in the student's calculation. \n",
      "\n",
      "Therefore, the student's solution is incorrect due to the error in the maintenance cost's variable component.\n",
      "</think>\n",
      "\n",
      "The student's solution is **incorrect**. \n",
      "\n",
      "**Error Analysis:**\n",
      "The maintenance cost has a variable component of **$10** per square foot, but the student incorrectly used **$100** per square foot (writing `100x` instead of `10x`). \n",
      "\n",
      "**Correct Calculation:**\n",
      "Let \\( x \\) = size of the installation (sq ft).  \n",
      "Total cost = Land cost + Solar panel cost + Maintenance cost  \n",
      "= \\( 100x + 250x + (100,\\!000 + 10x) \\)  \n",
      "= \\( (100 + 250 + 10)x + 100,\\!000 \\)  \n",
      "= **\\( 360x + 100,\\!000 \\)**  \n",
      "\n",
      "The student’s final expression \\( 450x + 100,\\!000 \\) overestimates the cost by **\\$90 per square foot** (due to their `100x` mistake in maintenance). \n",
      "\n",
      "**Conclusion:** The student's solution is incorrect due to an error in calculating the variable portion of the maintenance cost.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need \n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \n",
    "me a flat $100k per year, and an additional $10 / square \n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that the student's solution is actually not correct.\n",
    "#### We can fix this by instructing the model to work out its own solution first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:56: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:56: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/tmp/ipykernel_10156/1709959923.py:56: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's tackle this problem step by step. The goal is to find the total cost for the first year as a function of the number of square feet, which we'll call x.\n",
      "\n",
      "First, let me list all the costs mentioned:\n",
      "\n",
      "1. Land cost: The problem says land is $100 per square foot. So for x square feet, that would be 100 multiplied by x. That part seems straightforward.\n",
      "\n",
      "2. Solar panels: These cost $250 per square foot. So similar to land, that's 250 times x. Adding that to the land cost gives us 100x + 250x so far. \n",
      "\n",
      "3. Maintenance: There's a flat fee of $100,000 per year plus an additional $10 per square foot. Wait, the problem states \"$10 / square foot\" for the maintenance. So the maintenance cost should be 100,000 plus 10x. \n",
      "\n",
      "Now adding all these together. Let's break it down:\n",
      "\n",
      "Land: 100x\n",
      "Panels: 250x\n",
      "Maintenance: 100,000 + 10x\n",
      "\n",
      "Adding the terms:\n",
      "\n",
      "First, combine the x terms from land, panels, and maintenance. That would be (100 + 250 + 10)x. Let me check the numbers again. Land is 100, panels 250, and maintenance's variable part is 10. So 100 + 250 is 350, plus 10 is 360. So 360x. \n",
      "\n",
      "Then the fixed cost is just the maintenance's flat fee of 100,000. \n",
      "\n",
      "So total cost should be 360x + 100,000.\n",
      "\n",
      "Wait a minute, the student's solution had 450x + 100,000. Oh, where did they get 450? Let's see their breakdown. \n",
      "\n",
      "They listed maintenance as 100,000 + 100x. Wait, their maintenance cost has 100x, but according to the problem, the maintenance's per square foot is $10, not $100. That's a mistake. \n",
      "\n",
      "The problem statement says the maintenance has a flat $100k and an additional $10/sq ft. So the maintenance's variable part is 10x, not 100x. The student probably misread that and used $100 instead of $10. \n",
      "\n",
      "So their maintenance cost was incorrectly calculated. Let's recalculate with their error:\n",
      "\n",
      "If maintenance is 100,000 + 100x, then adding all parts:\n",
      "\n",
      "Land (100x) + Panels (250x) + Maintenance (100,000 + 100x) equals 100+250+100 = 450x + 100k. Which is what they have, but their mistake is the $10 vs $100.\n",
      "\n",
      "Therefore, the correct total cost should be 360x + 100,000. The student's solution is incorrect because they added 100x for maintenance instead of 10x. \n",
      "\n",
      "So the answer is that the student's solution is wrong.\n",
      "</think>\n",
      "\n",
      "Actual solution:\n",
      "```\n",
      "Let x = number of square feet.\n",
      "\n",
      "Land cost: 100x  \n",
      "Solar panels: 250x  \n",
      "Maintenance: 100,000 + 10x  \n",
      "\n",
      "Total cost = (100x + 250x) + (100,000 + 10x)  \n",
      "= 360x + 100,000\n",
      "```\n",
      "\n",
      "Is the student's solution the same as actual solution just calculated:\n",
      "```\n",
      "no\n",
      "```\n",
      "\n",
      "Student grade:\n",
      "```\n",
      "incorrect\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem including the final total. \n",
    "- Then compare your solution to the student's solution \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help \n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \n",
    "me a flat $100k per year, and an additional $10 / square \n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Limitations: Hallucinations\n",
    "- Boie is a real company, the product name is not real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alishaik/anaconda3/envs/lanchain_py_latest/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "HfHubHTTPError",
     "evalue": "500 Server Error: Internal Server Error for url: https://router.huggingface.co/hf-inference/models/Qwen/QwQ-32B/v1/chat/completions (Request ID: Root=1-67d3174b-0b44558522405b337fa5ed3f;98b687a2-5fa9-48ba-a50b-37824673de89)\n\nModel too busy, unable to get response in less than 60 second(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lanchain_py_latest/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lanchain_py_latest/lib/python3.13/site-packages/requests/models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 500 Server Error: Internal Server Error for url: https://router.huggingface.co/hf-inference/models/Qwen/QwQ-32B/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mTell me about AeroGlide UltraSlim Smart Toothbrush by dabur\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mget_completion\u001b[39m\u001b[34m(prompt, model)\u001b[39m\n\u001b[32m     13\u001b[39m llm=HuggingFaceEndpoint(repo_id=model,\n\u001b[32m     14\u001b[39m                     task=\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m                     )\n\u001b[32m     16\u001b[39m model=ChatHuggingFace(llm=llm)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m result=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lanchain_py_latest/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:285\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    275\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    276\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    280\u001b[39m     **kwargs: Any,\n\u001b[32m    281\u001b[39m ) -> BaseMessage:\n\u001b[32m    282\u001b[39m     config = ensure_config(config)\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    284\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    295\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lanchain_py_latest/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:861\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    854\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    855\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    858\u001b[39m     **kwargs: Any,\n\u001b[32m    859\u001b[39m ) -> LLMResult:\n\u001b[32m    860\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lanchain_py_latest/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:691\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    689\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    690\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m691\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m         )\n\u001b[32m    698\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    699\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lanchain_py_latest/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:926\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    930\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lanchain_py_latest/lib/python3.13/site-packages/langchain_huggingface/chat_models/huggingface.py:370\u001b[39m, in \u001b[36mChatHuggingFace._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m _is_huggingface_endpoint(\u001b[38;5;28mself\u001b[39m.llm):\n\u001b[32m    369\u001b[39m     message_dicts = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m     answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(answer)\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lanchain_py_latest/lib/python3.13/site-packages/huggingface_hub/inference/_client.py:956\u001b[39m, in \u001b[36mInferenceClient.chat_completion\u001b[39m\u001b[34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[39m\n\u001b[32m    928\u001b[39m parameters = {\n\u001b[32m    929\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: payload_model,\n\u001b[32m    930\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   (...)\u001b[39m\u001b[32m    947\u001b[39m     **(extra_body \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    948\u001b[39m }\n\u001b[32m    949\u001b[39m request_parameters = provider_helper.prepare_request(\n\u001b[32m    950\u001b[39m     inputs=messages,\n\u001b[32m    951\u001b[39m     parameters=parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     api_key=\u001b[38;5;28mself\u001b[39m.token,\n\u001b[32m    955\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    959\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lanchain_py_latest/lib/python3.13/site-packages/huggingface_hub/inference/_client.py:321\u001b[39m, in \u001b[36mInferenceClient._inner_post\u001b[39m\u001b[34m(self, request_parameters, stream)\u001b[39m\n\u001b[32m    318\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.iter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response.content\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lanchain_py_latest/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:481\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mHfHubHTTPError\u001b[39m: 500 Server Error: Internal Server Error for url: https://router.huggingface.co/hf-inference/models/Qwen/QwQ-32B/v1/chat/completions (Request ID: Root=1-67d3174b-0b44558522405b337fa5ed3f;98b687a2-5fa9-48ba-a50b-37824673de89)\n\nModel too busy, unable to get response in less than 60 second(s)"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by dabur\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lanchain_py_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
